{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LLD_32x32_icons_DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satrfall6/GAN_LLD_32x32/blob/master/LLD_32x32_icons_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCJvYAfjyW95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJnBPV3S2WuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as opt\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "#for loading data\n",
        "import h5py\n",
        "import torch.utils.data as tud"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhFZvtV8GNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size during training\n",
        "batch_size = 64\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 32\n",
        "# Number of training epochs\n",
        "num_epochs =10\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 0\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0003"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNp4HZsOLIwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if GPU is working \n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB421obUMFWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set the GPU device, then we can apply for the parameters below\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsI8IEBWtF6Q",
        "colab_type": "text"
      },
      "source": [
        "##loading and preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC_5REnIzAId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Image loading and processing: load data from HDF5\n",
        "transform=transforms.Compose([\n",
        "                               transforms.ToPILImage(),\n",
        "                               transforms.Resize(image_size),#\n",
        "                               transforms.CenterCrop(image_size),#\n",
        "\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ])\n",
        "\n",
        "class loadHDF5(tud.Dataset):\n",
        "    '''\n",
        "    this will output the [n,3,32,32] tensor without normalizing \n",
        "    '''\n",
        "    def __init__(self, file_path,transform=None):\n",
        "        super(loadHDF5, self).__init__()\n",
        "        h5_file = h5py.File(file_path)\n",
        "        self.data = h5_file.get('data')\n",
        "        self.target = h5_file.get('label')\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self):   \n",
        "\n",
        "        return torch.from_numpy((self.data[:,:,:,:])).float()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "      \n",
        "ld5=loadHDF5('/content/drive/My Drive/Colab Notebooks/LLD_32/LLD-icon.hdf5')\n",
        "img = ld5.__getitem__()\n",
        "\n",
        "outputs = []\n",
        "for i,ch in enumerate(range(img.size(0)), 0):\n",
        "    tensor = transform(img[ch,:,:,:])\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    outputs.append(tensor)\n",
        "icons_32_32_1 = torch.cat(outputs, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fWeSr1rzYvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(icons_32_32, '/content/drive/My Drive/Colab Notebooks/LLD_32/icon_sharp.pt')\n",
        "torch.save(icons_32_32_1, '/content/drive/My Drive/Colab Notebooks/LLD_32/icon_32.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoSOxUHv3E34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "icons_32_32=torch.load( '/content/drive/My Drive/Colab Notebooks/LLD_32/icon_sharp.pt')\n",
        "icons_32_32_1=torch.load( '/content/drive/My Drive/Colab Notebooks/LLD_32/icon_32.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aghnE_BPFxs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "icon_combined = torch.cat((icons_32_32_1,icons_32_32), dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auI8r4yQ11pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(icon_combined, '/content/drive/My Drive/Colab Notebooks/LLD_32/icon_combined.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un3BKWTX0Mhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#have saved the combined data, just load this term\n",
        "icon_combined=torch.load( '/content/drive/My Drive/Colab Notebooks/LLD_32/icon_combined.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9MkIv4p0Sn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "icon_combined.shape\n",
        "#icon_combined[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM10JUBi2tbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wrap up the images in dataloader\n",
        "\n",
        "LLDLoader = torch.utils.data.DataLoader(icon_combined, shuffle=True, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAvyaPPocVyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot 64(8*8) images in one plot\n",
        "def showImages(imgs):\n",
        "    imgs = torchvision.utils.make_grid(imgs)\n",
        "    npimgs = imgs.cpu()\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(np.transpose(npimgs, (1,2,0)), cmap='Greys_r')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C-5WfZR21Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize weights 'CONV' and 'Batch' by normal distribution with(mean,std) \n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0., 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1., 0.02)\n",
        "        m.bias.data.fill_(0.)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iW4RCUB3D03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generator\n",
        "\n",
        "\n",
        "class generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self):\n",
        "        super(generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 4, 4, 1, 0, bias=False), \n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False), \n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf * 1, 4, 2, 1, bias=False), \n",
        "            nn.BatchNorm2d(ngf * 1),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*1) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), \n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 32 x 32\n",
        "            )\n",
        "        \n",
        "            # forward method\n",
        "    def forward(self, input):\n",
        "\n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja7nQgYs3RYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#discriminator\n",
        "   \n",
        "class discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 32 x 32\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 16 x 16\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 8 x 8\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),  \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "            # forward method\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5xgE1Fg3TkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model\n",
        "G=generator()\n",
        "D=discriminator()\n",
        "\n",
        "#set the loss function\n",
        "criterion = nn.BCELoss()\n",
        "fixed_noise = torch.randn(64, nz, 1, 1).to(device) \n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = opt.Adam(D.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = opt.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "#just for tracing the performance of model\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra69frpTCH22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set model to GPU\n",
        "D.cuda()\n",
        "G.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt24Q4Fr3ph2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#apply initialize weights\n",
        "#G.apply(weights_init)\n",
        "#D.apply(weights_init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0H3GSdCbCJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#apply saved weights\n",
        "stateG_icon32x32=torch.load('/content/drive/My Drive/Colab Notebooks/LLD_32/G_icon_new')\n",
        "G.load_state_dict(stateG_icon32x32['state_dict'])\n",
        "optimizerG.load_state_dict(stateG_icon32x32['optimizer'])\n",
        "\n",
        "stateD_icon32x32=torch.load('/content/drive/My Drive/Colab Notebooks/LLD_32/D_icon_new')\n",
        "D.load_state_dict(stateD_icon32x32['state_dict'])\n",
        "optimizerD.load_state_dict(stateD_icon32x32['optimizer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FS5ahW03zih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(LLDLoader, 0):\n",
        "#        X, _ = data #just for debugging\n",
        "        '''\n",
        "        ###########################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ### Train with all-real batch\n",
        "        '''\n",
        "        # Firstly, have to set grad to zero\n",
        "        D.zero_grad()\n",
        "        ## Format batch\n",
        "        #different from MNIST, our data structure do not have label \n",
        "        real_img = data.to(device) \n",
        "        # Set the batch size same as the image batch size we input every time\n",
        "        #sometimes it would not be same as the setting at original e.g.64, 60000/64 will left 32)\n",
        "        b_size = real_img.size(0)\n",
        "        # Create the label for images from true dataset   \n",
        "        one_label = torch.full((b_size,), real_label).to(device)  \n",
        "        # Forward pass real batch through D\n",
        "        output = D(real_img).view(-1).to(device) \n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, one_label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "        \n",
        "        '''\n",
        "        ###################################\n",
        "        ## Train D with all-fake batch\n",
        "        ###################################\n",
        "        '''                \n",
        "\n",
        "        # Generate batch of latent vectors(100-vector)\n",
        "        noise = torch.randn(b_size, nz, 1, 1).to(device) \n",
        "        # Generate fake image batch with G\n",
        "        fake = G(noise)\n",
        "\n",
        "        zero_label = torch.full((b_size,), fake_label).to(device) \n",
        "        # Classify all fake batch with D\n",
        "        output = D(fake.detach()).view(-1).to(device) \n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, zero_label)\n",
        "        # Calculate the gradients for this batch\n",
        "        errD_fake.backward()\n",
        "     \n",
        "        ########### for statistics ############\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = errD_real + errD_fake\n",
        "        #######################################\n",
        "        \n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "        '''\n",
        "        ###########################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        '''\n",
        "        G.zero_grad()\n",
        "\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "\n",
        "        output = D(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, one_label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        \n",
        "        ########### for statistics ############\n",
        "        D_G_z2 = output.mean().item()\n",
        "        #######################################\n",
        "        \n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "        \n",
        "        \n",
        "        if i % 3450 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(LLDLoader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "        \n",
        "        \n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(trainLoader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = G(fixed_noise).detach()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1  \n",
        "        \n",
        "        if epoch % 1==0:\n",
        "            #samples = fake.detach()\n",
        "            #samples = samples.view(samples.size(0), 3, 32, 32)\n",
        "            #showImages(samples)\n",
        "\n",
        "            stateG_icon32x32 = {\n",
        "                'epoch': epoch,\n",
        "                'state_dict': G.state_dict(),\n",
        "                'optimizer': optimizerG.state_dict(),\n",
        "\n",
        "            }\n",
        "            torch.save(stateG_icon32x32, '/content/drive/My Drive/Colab Notebooks/LLD_32/G_icon_new')\n",
        "            \n",
        "            stateD_icon32x32 = {\n",
        "                'epoch': epoch,\n",
        "                'state_dict': D.state_dict(),\n",
        "                'optimizer': optimizerD.state_dict(),\n",
        "\n",
        "            }\n",
        "            torch.save(stateD_icon32x32, '/content/drive/My Drive/Colab Notebooks/LLD_32/D_icon_new')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1nhNTxl20Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i, epoch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TBhp6miSZyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#manully plot\n",
        "b_size=64\n",
        "noise = torch.randn(b_size, nz, 1, 1).to(device) \n",
        "# Generate fake image batch with G\n",
        "fake = G(noise)\n",
        "samples = fake.detach()\n",
        "samples = samples.view(samples.size(0), 3, 32, 32)\n",
        "showImages(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eYGoSm8da7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save weight manually\n",
        "\n",
        "stateG_icon32x32 = {\n",
        "    'epoch': epoch,\n",
        "    'state_dict': G.state_dict(),\n",
        "    'optimizer': optimizerG.state_dict(),\n",
        "\n",
        "}\n",
        "torch.save(stateG_icon32x32, '/content/drive/My Drive/Colab Notebooks/LLD_32/G_icon_new') \n",
        "stateD_icon32x32 = {\n",
        "    'epoch': epoch,\n",
        "    'state_dict': D.state_dict(),\n",
        "    'optimizer': optimizerD.state_dict(),\n",
        "\n",
        "}\n",
        "torch.save(stateD_icon32x32, '/content/drive/My Drive/Colab Notebooks/LLD_32/D_icon_new')\n",
        "\n",
        "print(\"saved successfully\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FydclSHkXPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}