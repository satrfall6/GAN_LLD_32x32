# -*- coding: utf-8 -*-
"""LLD_32x32_icons_DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cazeNpXrJRorT9YmtHj8f76udH7usdWj
"""


import torch
import torch.optim as opt
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from torch.nn import functional as F
import numpy as np
from sklearn.cluster import KMeans
import os
from torch.nn.utils import spectral_norm




#%%
#check if GPU is working and set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device
       


#%%
#have stored the image data in .pt file, just load from it
#change to the path that saves pre-processed image and the pre-trainined weights
document = os.path.join(os.path.expanduser("~"), "/Users/s4503302/Documents/LLD_DCGAN")
loadPath_2x = os.path.join(document, "icon_2x.pt")
loadPath_4x = os.path.join(document, "icon_4x.pt")
#%%
#load seperately
image_size = 32
icons_32_4x=torch.load(loadPath_4x)
icons_32_2x=torch.load(loadPath_2x)
#combine for training the entire dataset 
icon_combined = torch.cat((icons_32_2x,icons_32_4x), dim=0)
icons_32_4x = None
icons_32_2x = None
LLDloader = torch.utils.data.DataLoader(icon_combined, shuffle=True, batch_size=64)
#%%
#plot 64(8*8) images in one plot
def showImages(imgs):
    imgs = imgs/2 + 0.5
    imgs = torchvision.utils.make_grid(imgs)
    npimgs = imgs.cpu()
    plt.figure(figsize=(8,8))
    plt.imshow(np.transpose(npimgs, (1,2,0)), interpolation='bicubic')
    plt.xticks([])
    plt.yticks([])
    plt.show()

#initialize weights 'CONV' and 'Batch' by normal distribution with(mean,std) 
def weights_init(m):
    torch.manual_seed(427)
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0., 0.02)
    elif classname.find('Linear') != -1:
        m.weight.data.normal_(0., 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1., 0.02)
        m.bias.data.fill_(0.)
        
#saving the images 
def saveImages(imgs,path):
    imgs = imgs/2 + 0.5
    imgs = torchvision.utils.make_grid(imgs)
    npimgs = imgs.cpu()
    plt.figure(figsize=(8,8))
    plt.imshow(np.transpose(npimgs, (1,2,0)), interpolation='bicubic')
    plt.xticks([])
    plt.yticks([])
    plt.savefig(path)
    plt.show()



##DCGAN using batchnorm

#generator
class generator(nn.Module):
    # initializers
    def __init__(self):
        super(generator, self).__init__()
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            spectral_norm(nn.ConvTranspose2d( nz, ngf * 4, 4, 1, 0, bias=False)), 
  
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ngf*4) x 4 x 4
            spectral_norm(nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False)), 
 
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ngf*2) x 8 x 8
            spectral_norm(nn.ConvTranspose2d( ngf * 2, ngf * 1, 4, 2, 1, bias=False)), 
  
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ngf*1) x 16 x 16
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), 
            nn.BatchNorm2d(nc),
            nn.Tanh()
            # state size. (nc) x 32 x 32
            )
        
            # forward method
    def forward(self, input):

        return self.main(input)

#discriminator   
class discriminator(nn.Module):
    # initializers
    def __init__(self):
        super(discriminator, self).__init__()
        self.main = nn.Sequential(
            # input is (nc) x 32 x 32
            spectral_norm(nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)), 
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 16 x 16
            spectral_norm(nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False)),
   
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 8 x 8
            spectral_norm(nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)),

            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 4 x 4
            spectral_norm(nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False)),  
            nn.Sigmoid()
        )

            # forward method
    def forward(self, input):
        return self.main(input)


# Batch size during training
batch_size = 64

# Number of training epochs
num_epochs =76
# Number of channels in the training images. For color images this is 3
nc = 3
# Size of z latent vector (i.e. size of generator input)
nz = 100
# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64

# adjust label smoothing here
real_label = 0.94
fake_label = 0.03


#just for tracing the performance of model
G_losses = []
D_losses = []

#save the model        
G=generator().to(device)
D=discriminator().to(device)

criterion = nn.BCELoss()

# Setup Adam optimizers for both G and D
optimizerD = opt.Adam(D.parameters(), lr=0.00042, betas=(0.9, 0.999))
optimizerG = opt.Adam(G.parameters(), lr=0.000065, betas=(0.9, 0.999))

#fixed size of noise for plotting manually or testing 
fixed_noise = torch.randn(64, nz, 1, 1).to(device) 


#%%
# apply initialize weights 
'''
G.apply(weights_init)
D.apply(weights_init)
'''

##path for loading and saving the weight for training
#weights with SN, without adding noise
G_weightsPath = os.path.join(document,               "G_SNG4CBN_SND4C_2x_nz100gf64_Glr000065_Dlr00042")
D_weightsPath = os.path.join(document,               "D_SNG4CBN_SND4C_2x_nz100gf64_Glr000065_Dlr00042")
#%%
#weights with SN and adding noise
G_weightsPath = os.path.join(document,               "G_SNG4CBN_SND4CNoise_2x_nz100gf64_Glr000065_Dlr00042_L88_05")
D_weightsPath = os.path.join(document,               "D_SNG4CBN_SND4CNoise_2x_nz100gf64_Glr000065_Dlr00042_L88_05")
#%%
#weights with SN and adding noise, training progressively using 4 clusters from KMeans
G_weightsPath = os.path.join(document,               "G_SNG4CBN_SND4CNoise_c0c3c2c1_nz100gf64_Glr000065_Dlr00042_L88_05")
D_weightsPath = os.path.join(document,               "D_SNG4CBN_SND4CNoise_c0c3c2c1_nz100gf64_Glr000065_Dlr00042_L88_05")
#%%
# or load the pre-trained weights
stateG_icon32x32=torch.load(G_weightsPath,map_location=torch.device('cpu'))
G.load_state_dict(stateG_icon32x32['state_dict'])
optimizerG.load_state_dict(stateG_icon32x32['optimizer'])
epoch_last = stateG_icon32x32['epoch']
G_losses = stateG_icon32x32["G_losses"]
   
stateD_icon32x32=torch.load(D_weightsPath,map_location=torch.device('cpu'))
D.load_state_dict(stateD_icon32x32['state_dict'])
optimizerD.load_state_dict(stateD_icon32x32['optimizer'])
D_losses = stateD_icon32x32["D_losses"]
num_epochs-=epoch_last


#manully plot
torch.manual_seed(428)
samples = G(fixed_noise).detach()
showImages(samples[0:64])

#%%
#train the DCGAN, if not training, ignore this part
for epoch in range(num_epochs):
    # For each batch in the dataloader
    running_lossG=[]
    running_lossD=[]
    for i, data in enumerate(LLDloader, 0):

        '''
        ###########################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################
        '''
  
        '''
        ## Train with all-real batch
        '''
        # Firstly, have to set grad to zero
        
        ## Format batch
         
        real_img = data.to(device) 
        #adding noise to the real image
        real_img = real_img+torch.randn(real_img.size()).to(device)*0.1
        # Set the batch size same as the image batch size we input every time
        #sometimes it would not be same as the setting at original e.g.64, 60000/64 will left 32)
        b_size = real_img.size(0)
        # Create the label for images from true dataset   
        one_label = torch.full((b_size,), real_label).to(device) 
        zero_label = torch.full((b_size,), fake_label).to(device)
        noise = torch.randn(b_size, nz, 1, 1).to(device)
        
        D.zero_grad()
        G.zero_grad()
        # Forward pass real batch through D & G
        D_real = D(real_img).view(-1).to(device) 
        fake = G(noise)
        #add noise to image from the generator
        fake = fake+torch.randn(fake.size()).to(device)*0.16
        D_fake = D(fake).view(-1).to(device)                                                   
                                                          
        # Calculate loss on all-real batch
        D_loss_real = criterion(D_real, one_label)
        D_loss_fake = criterion(D_fake, zero_label)
        D_loss = D_loss_real + D_loss_fake                                                  
        # Calculate gradients for D in backward pass
        D_loss.backward()                                                            
        optimizerD.step()
                                                                
        '''
        ###########################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        '''

        # Since we just updated D, perform another forward pass of all-fake batch through D
        noise = torch.randn(b_size, nz, 1, 1).to(device)
        fake = G(noise)
        #add noise to image from the generator
        fake = fake+torch.randn(fake.size()).to(device)*0.16
        D_fake = D(fake).view(-1).to(device)                                                   

        # Calculate G's loss based on this output
        G_loss = criterion(D_fake, one_label)
        # Calculate gradients for G
        G_loss.backward()
        optimizerG.step()
                                                          
                                                          
        ########### for statistics ############
        D_Gz = D_fake.mean().item()
        D_x = D_real.mean().item()                                                  
        #######################################
        
        
        
        

        #showing the statistics
        if i % 1500 == 0:
            print('[%d/%d][%d/%d]\t\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)):%.4f'
                   % (epoch, num_epochs, i, len(LLDloader),
                     D_loss.item(), G_loss.item(), D_x, D_Gz))
            running_lossG.append(G_loss.item())
            running_lossD.append(D_loss.item())
    # Save Losses for plotting later
    if epoch % 1==0:       
        G_losses.append(np.mean(running_lossG))
        D_losses.append(np.mean(running_lossD))
              
    #save weights for preventing interrupting     
    if epoch % 3==0:
        stateG_icon32x32 = {
            'epoch': epoch,
            'state_dict': G.state_dict(),
            'optimizer': optimizerG.state_dict(),
        }
        torch.save(stateG_icon32x32, G_weightsPath)

        stateD_icon32x32 = {
            'epoch': epoch,
            'state_dict': D.state_dict(),
            'optimizer': optimizerD.state_dict(),
        }
        torch.save(stateD_icon32x32, D_weightsPath)
        print("saved successfully")
    #show the ongoing generated images to make sure the model work properly   
    if epoch % 5==0:      
        samples = G(fixed_noise).detach()        
        showImages(samples[0:64])


##end process
#path for saving plot of loss and generated images        
Loss_savePath =  os.path.join(document,           "Loss_G4C_D4C_2x_nz100gf64_Glr000065_Dlr00042_L88_05")
Generated_savePath =  os.path.join(document, "Generated_G4C_D4C_2x_nz100gf64_Glr000065_Dlr00042_L88_05")
        
font = {
        'color':  'blue',
        'size': 16,
        }

plt.figure()    
plt.plot(G_losses,label = "Loss of G")
plt.plot(D_losses,label = "Loss of D")
plt.legend(loc="best")
plt.title("Loss of discriminator and gernerator after %.0f epochs" % (epoch),fontdict=font)
plt.xlabel('Number of Epochs',fontdict=font)
plt.ylabel('Loss of D and G',fontdict=font)
plt.savefig(Loss_savePath)
plt.show()


samples = G(fixed_noise).detach()
saveImages(samples[0:64],Generated_savePath)
