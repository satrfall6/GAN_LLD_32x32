# -*- coding: utf-8 -*-
"""LLD_32x32_icons_DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cazeNpXrJRorT9YmtHj8f76udH7usdWj
"""


import torch
import torch.optim as opt
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from torch.nn import functional as F
import torchvision.utils as vutils
import numpy as np
from sklearn.cluster import KMeans
import os
from torch.utils.checkpoint import checkpoint



#%%
#check if GPU is working and set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device



       
#%%


#%%
loadPath_2x = os.path.join(document, "icon_2x.pt")
loadPath_4x = os.path.join(document, "icon_4x.pt")

#load seperately
image_size = 32
icons_32_4x=torch.load(loadPath_4x)
icons_32_2x=torch.load(loadPath_2x)
#combine for training the entire dataset 
icon_combined = torch.cat((icons_32_2x,icons_32_4x), dim=0)
icons_32_4x = None
icons_32_2x = None
LLDloader = torch.utils.data.DataLoader(icon_combined, shuffle=True, batch_size=64)
#%%
#plot 64(8*8) images in one plot
def showImages(imgs):
    imgs = imgs/2 + 0.5
    imgs = torchvision.utils.make_grid(imgs)
    npimgs = imgs.cpu()
    plt.figure(figsize=(8,8))
    plt.imshow(np.transpose(npimgs, (1,2,0)), interpolation='bicubic')
    plt.xticks([])
    plt.yticks([])
    plt.show()

#initialize weights 'CONV' and 'Batch' by normal distribution with(mean,std) 
def weights_init(m):
    torch.manual_seed(427)
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0., 0.02)
    elif classname.find('Linear') != -1:
        m.weight.data.normal_(0., 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1., 0.02)
        m.bias.data.fill_(0.)
        
#saving the images 
def saveImages(imgs,path):
    imgs = imgs/2 + 0.5
    imgs = torchvision.utils.make_grid(imgs)
    npimgs = imgs.cpu()
    plt.figure(figsize=(8,8))
    plt.imshow(np.transpose(npimgs, (1,2,0)), interpolation='bicubic')
    plt.xticks([])
    plt.yticks([])
    plt.savefig(path)
    plt.show()

#%%
##DCGAN part

# Batch size during training
batch_size = 64

# Number of training epochs
num_epochs =76
# Number of channels in the training images. For color images this is 3
nc = 3
# Size of z latent vector (i.e. size of generator input)
nz = 100
# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64


#generator
class generator(nn.Module):

    # initializers
    def __init__(self):
        super(generator, self).__init__()
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 4, 4, 1, 0, bias=False), 
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 4 x 4
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False), 
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 8 x 8
            nn.ConvTranspose2d( ngf * 2, ngf * 1, 4, 2, 1, bias=False), 
            nn.BatchNorm2d(ngf * 1),
            nn.ReLU(True),
            # state size. (ngf*1) x 16 x 16
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), 
            nn.Tanh()
            # state size. (nc) x 32 x 32
            )
        
            # forward method
    def forward(self, input):

        return self.main(input)

#discriminator   
class discriminator(nn.Module):
    # initializers
    def __init__(self):
        super(discriminator, self).__init__()
        self.main = nn.Sequential(
            # input is (nc) x 32 x 32
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), 
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 16 x 16
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 8 x 8
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 4 x 4
            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),  
            nn.Sigmoid()
        )

            # forward method
    def forward(self, input):
        return self.main(input)


#save the model
G=generator().to(device)
D=discriminator().to(device)

#set the loss function
criterion = nn.BCELoss()

# Setup Adam optimizers for both G and D
optimizerD = opt.Adam(D.parameters(), lr=0.00042, betas=(0.9, 0.999))
optimizerG = opt.Adam(G.parameters(), lr=0.00065, betas=(0.9, 0.999))

#fixed size of noise for plotting manually or testing 
fixed_noise = torch.randn(64, nz, 1, 1).to(device) 

# Establish convention for real and fake labels during training
real_label = 1
fake_label = 0


#just for tracing the performance of model
G_losses = []
D_losses = []

applied = 0



#%%
#apply initialize weights
G.apply(weights_init)
D.apply(weights_init)
applied = 1
print(" ")


#%%
#path for loading and saving the weight for training
G_weightsPath = os.path.join(document,               "G_G4C_D4C_7x_nz256gf64")
D_weightsPath = os.path.join(document,               "D_G4C_D4C_7x_nz256gf64")
Loss_savePath =  os.path.join(document,           "Loss_G4C_D4C_7x_nz256gf64")
Generated_savePath =  os.path.join(document, "Generated_G4C_D4C_7x_nz256gf64")

#load the parameters from last training 
if applied != 1:
    stateG_icon32x32=torch.load(G_weightsPath)
    G.load_state_dict(stateG_icon32x32['state_dict'])
    optimizerG.load_state_dict(stateG_icon32x32['optimizer'])
    epoch_last = stateG_icon32x32['epoch']
    G_losses = stateG_icon32x32["G_losses"]
       
    stateD_icon32x32=torch.load(D_weightsPath)
    D.load_state_dict(stateD_icon32x32['state_dict'])
    optimizerD.load_state_dict(stateD_icon32x32['optimizer'])
    D_losses = stateD_icon32x32["D_losses"]
    num_epochs-=epoch_last
    

for epoch in range(num_epochs):
    # For each batch in the dataloader
    running_lossG=[]
    running_lossD=[]
    for i, data in enumerate(LLDloader, 0):

        '''
        ###########################
        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
        ###########################
        '''
  
        '''
        ## Train with all-real batch
        '''
        # Firstly, have to set grad to zero
        
        ## Format batch
        #different from MNIST, our data structure do not have label 
        real_img = data.to(device) 
        # Set the batch size same as the image batch size we input every time
        #sometimes it would not be same as the setting at original e.g.64, 60000/64 will left 32)
        b_size = real_img.size(0)
        # Create the label for images from true dataset   
        one_label = torch.full((b_size,), real_label).to(device) 
        zero_label = torch.full((b_size,), fake_label).to(device)
        noise = torch.randn(b_size, nz, 1, 1).to(device)
        
        D.zero_grad()
        G.zero_grad()
        # Forward pass real batch through D & G
        D_real = D(real_img).view(-1).to(device) 
        fake = G(noise)
        D_fake = D(fake).view(-1).to(device)                                                   
                                                          
        # Calculate loss on all-real batch
        D_loss_real = criterion(D_real, one_label)
        D_loss_fake = criterion(D_fake, zero_label)
        D_loss = D_loss_real + D_loss_fake                                                  
        # Calculate gradients for D in backward pass
        D_loss.backward()                                                            
        optimizerD.step()
                                                                
        '''
        ###########################
        # (2) Update G network: maximize log(D(G(z)))
        ###########################
        '''

        # Since we just updated D, perform another forward pass of all-fake batch through D
        noise = torch.randn(b_size, nz, 1, 1).to(device)
        fake = G(noise)
        D_fake = D(fake).view(-1).to(device)                                                   

        # Calculate G's loss based on this output
        G_loss = criterion(D_fake, one_label)
        # Calculate gradients for G
        G_loss.backward()
        optimizerG.step()
                                                          
                                                          
        ########### for statistics ############
        D_Gz = D_fake.mean().item()
        D_x = D_real.mean().item()                                                  
        #######################################
        
        
        
        

        #showing the statistics
        if i % 1500 == 0:
            print('[%d/%d][%d/%d]\t\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)):%.4f'
                   % (epoch, num_epochs, i, len(LLDloader),
                     D_loss.item(), G_loss.item(), D_x, D_Gz))
            running_lossG.append(G_loss.item())
            running_lossD.append(D_loss.item())
    # Save Losses for plotting later
    if epoch % 1==0:       
        G_losses.append(np.mean(running_lossG))
        D_losses.append(np.mean(running_lossD))
              
    #save weights for preventing interrupting     
    if epoch % 3==0:
        stateG_icon32x32 = {
            'epoch': epoch,
            'state_dict': G.state_dict(),
            'optimizer': optimizerG.state_dict(),
        }
        torch.save(stateG_icon32x32, G_weightsPath)

        stateD_icon32x32 = {
            'epoch': epoch,
            'state_dict': D.state_dict(),
            'optimizer': optimizerD.state_dict(),
        }
        torch.save(stateD_icon32x32, D_weightsPath)
        print("saved successfully")
    #show the ongoing generated images to make sure the model work properly   
    if epoch % 5==0:      
        samples = G(fixed_noise).detach()        
        showImages(samples[0:64])


#end process
font = {
        'color':  'blue',
        'size': 16,
        }

plt.figure()    
plt.plot(G_losses,label = "Loss of G")
plt.plot(D_losses,label = "Loss of D")
plt.legend(loc="best")
plt.title("Loss of discriminator and gernerator after %.0f epochs" % (epoch),fontdict=font)
plt.xlabel('Number of Epochs',fontdict=font)
plt.ylabel('Loss of D and G',fontdict=font)
plt.savefig(Loss_savePath)
plt.show()


samples = G(fixed_noise).detach()
saveImages(samples[0:64],Generated_savePath)
