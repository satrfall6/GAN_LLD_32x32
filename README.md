
# Automatic Generation of Icons

## Description
This repository implement DCGAN and Conditional DCGAN to generate icons. The dataset is taken from [LLD-Large logo dataset](https://data.vision.ee.ethz.ch/sagea/lld/). GAN is a powerful generative model. Instead of taking the avergage of the original dataset, GAN can learn the distribution which is similar to the original dataset. However, GAN is notorious for its instability during training. In this study, we tested parameters of model that we can adjust, to stablize the model. Included the number of layers, learning rate, label smoothing, adding noise, and using spectral norm.

 In addition, we also compare the results of DCGAN to the conditional DCGAN. This dataset does not have labels. In order to implement conditional DCGAN, we use Gaussian Mixture Model to create 100 clusters and label the images based on which cluster they belong to. Then, we merge the labels into the convolution layers to train the model.

## Environment
* Python version: 3.7
* [torch version : 1.2.0](https://pytorch.org/)
* tests are run on colab notebook

## Contents
* [Dataloader with Transform](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/py%20files/loadHDF5.py) 
* [DCGAN](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/py%20files/DCGAN.py)
* [Autoencoder](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/py%20files/Autoencoder.py)  
* [GMM](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/py%20files/GMM.py)  
* [Conditional DCGAN](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/py%20files/CDCGAN_withSN%20.py)

### __Data Loader__ 
The data is stored as .hdf5 format, and we use this data loader to load the data. The dataloader is developed by . We added the transform into the data loader so it can resize, center, and normalize the image.



### __DCGAN__
In the DCGAN, we improve the stability of the model by 4 things. Firstly, We use Two Time-Scale Update Rule, which means by using different learning rate for the generator and the discrminator. Secondly, we add the spectral norm to each layer of the dscriminator and the generator. Thirdly, we add noise the the inputs of the discriminator. Finally, the set the real and fake labels to the numbers that are close to 0 and 1, instead of using exactly 0 and 1.



* Stucture of DCGAN:
![DCGAN](https://i.imgur.com/JpmG9km.png)
Figure 1. the structure of DCGAN.

### __Autoencoder__ 
By using the autoencoder, we can keep the relation between pixel and pixel, then we cluster the image from the latent space.

* Stucture of autoencoder:
![AE](https://i.imgur.com/ADThmZB.png)
Figure 2. After trainig the autoencoder, we only used the encoder part the pre-processed images.

### __GMM__
We use GMM to create 100 clusters, then label them from 1 to 100 base on which cluster the images belong to. The AIC and BIC of GMM is shown as below

* Labels from the GMM:\
![GMM](https://i.imgur.com/naQ5ICb.png) \
Figure 3. The images are labeled based on their clusters. 

* AIC and BIC of the GMM: \
![AICBIC](https://i.imgur.com/sAFcObS.png)\
Figure 4. The AIC and BIC of different numbers of clusters.

### __Conditional DCGAN__
The label from the GMM is coded as onehot label, and merged to the convolutional layers in the way as shown in Figure 5. 

* Stucture of Conditional DCGAN:
![CDCGAN](https://i.imgur.com/A8ehR9f.png)
Figure 5. The structure of Conditional DCGAN shows how the labels are merged. 

## Results

* Results of DCGAN:\
![resultDCGAN](https://i.imgur.com/tMJtQGI.png)\
Figure 6. The results generated by DCGAN are blurred.


* Results of Conditional DCGAN:\
![resultCDCGAN](https://i.imgur.com/DxxF7F5.png)\
Figure 7. The results generated by Conditional DCGAN are slightly clearer. 

## Re-produce the results 

I. loading the data

change the path here where "LLD-icon-sharp.hdf5" and "LLD-icon.hdf5" are in ['loadHDF5'](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/py%20files/loadHDF5.py).
```
document = os.path.join(os.path.expanduser("~"), "/path/file_name/")
loadHDF5_Path_2x = os.path.join(document, "LLD-icon-sharp.hdf5")
loadHDF5_Path_4x = os.path.join(document, "LLD-icon.hdf5")
```
Then implement the main and it will return combined dataset after transforming.

Or the transformed file which can be loaded directly by torch can be found [here](https://drive.google.com/drive/folders/1VtFPr7LQEHOjUly6oegF8H2xb5K6avuW?usp=sharing).



II. Load the differents pre-trained weights, all the pre-trained weights can be found [here](https://drive.google.com/drive/folders/1NbeFwU96zeSHSHk2T_92mBO_9KADvyZQ?usp=sharing).

```
Load_G_weightsPath = os.path.join(document,          "G_weightsPath of your folder")

Load_D_weightsPath = os.path.join(document,          "D_weightsPath of your folder")
```

III. Run the cells in notebook ["DCGAN_demo"](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/ipynb%20files). Notice that there are 3 types of structure in this noteboo, make sure the weights are corresponding to the specific type of DCGAN as shown in this notebook.

IV. For training part, one can either use another initialized weights or pre-trained weights as shown above. The training parts can be found at the bottom of ["DCGAN_demo"](https://github.com/satrfall6/GAN_LLD_32x32/blob/master/ipynb%20files). 




## Reference

[LLD - Large Logo Dataset](https://data.vision.ee.ethz.ch/sagea/lld/) by Alexander, Eirikur, Radu, Luc Van.



